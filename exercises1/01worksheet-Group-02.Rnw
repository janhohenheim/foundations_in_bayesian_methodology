\documentclass{article}



\usepackage{amsmath, amssymb}
\usepackage{natbib}
\usepackage{hyperref}
\usepackage{booktabs}
\usepackage{verbatim}
\usepackage{float}


\title{Foundations of Bayesian Methodology \\[0.5cm] \large Group 2}
\author{Andrea Staub \and Emanuel Mauch \and Guillaume Morlet \and Holly Vuarnoz \and Jan Hohenheim \and Sophie Haldemann}


\begin{document}
\maketitle

\section{Worksheet 01}
\subsection{Group tasks}
\subsubsection{Exercise 5 (Bayes theorem)}

Prove the conditional Bayes theorem:
\begin{equation}
    P(A|B, I) = \frac{P(B|A, I)P(A|I)}{P(B|I)}
\end{equation}


\subsubsection*{Proof}
This is a conditional version of Bayes' theorem, were $I$ is an additional piece of information (see STA421 Script, Chapter 1). 
We start with the definition of conditional probability:
\begin{equation}
    P(A|B, I) = \frac{P(A \cap B|I)}{P(B|I)}
\end{equation}

We know that conditional probability also satisfies:
\begin{equation}
    P(B|A, I) = \frac{P(A \cap B|I)}{P(A|I)}
\end{equation}

Rearranging terms, we get:
\begin{equation}
    P(A \cap B|I) = P(B|A, I) \cdot P(A|I)
\end{equation}

Substituting back into our original equation, we get:
\begin{equation}
    P(A|B, I) = \frac{P(B|A, I) \cdot P(A|I)}{P(B|I)}
\end{equation}

This completes the proof of the conditional Bayes theorem. It shows how to update the probability of an event $A$ given the occurrence of another event $B$ and additional information $I$, using prior probabilities and the likelihood of $B$ given $A$ and $I$.

\end{document}
